{% extends "midocs/page_base.html" %}{% load mi_tags %}{% block content %}
{% index_entry "dynamical system" "definition" %}
{% title "Dynamical system definition" %}
{% description "A dynamical system is a system whose state evolves with time over a state space according to a fixed rule." %}

<p>A dynamical system is a system whose state evolves with time over a {% intlink state_space_definition %}state space{%endintlink%} according to a fixed rule.</p>

<p>For an introduction into the concepts behind a dynamical system, see the {% intlink dynamical_system_idea %}idea of a dynamical system{%endintlink%}.</p>

{% navigation_tag "formal" "Formal definition" %}
<h4>Formal definition of dynamical system</h4>

<p>A dynamical system is formally defined as a state space $X$, a set of times $T$, and a rule $R$ that specifies how the state evolves with time.  The rule $R$ is a function whose {% intlink domain_definition %}domain{%endintlink%} is $X \times T$ {% confusedlink cartesian_product_definition %} and whose {% intlink codomain_definition %}codomain{%endintlink%} is $X$, i.e., $R : X \times T \to X$ {% confusedlink function_notation %}. The rule function $R$ means that the $R$ takes two inputs, $R=R(\vc{x},t)$, where $\vc{x} \in X$ {% confusedlink set_membership_symbol_definition %}  is the initial state (at time $t=0$, for example) and $t \in T$ is a future time.  In other words, $R(\vc{x},t)$ gives the state at time $t$ given that the initial state was $\vc{x}$.</p>

{% endblock%}
